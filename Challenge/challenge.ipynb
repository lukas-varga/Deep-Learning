{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"colab":{"name":"challenge.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VtWyp7GJoLF9"},"source":["# Deep Learning challenge"]},{"cell_type":"markdown","metadata":{"id":"65k_qbmu_Z_g"},"source":["## Authors\n","\n","Lukáš Varga\n","\n","Francesco Maberino"]},{"cell_type":"markdown","metadata":{"id":"Ar37SdSsoLF-"},"source":["## Objective\n","The objective of this challenge is to develop a deep learning based classification method to classify images from [Google Quickdraw](https://quickdraw.withgoogle.com/data).\n","\n","\n","## Data \n","Among all the available images, you will work on a dataset composed of 5 balanced classes, with 15000 training examples and 5000 test examples: baskets, eyes, glasses, rabbits and hands. The archive *Data_train_test.zip* contains the set of images, as well as two CSV files, giving the lists of images used for the training/test step. \n","\n","## Methodology\n","You can use any algorithm that seems relevant to you (MLP, CNN, LSTM, transfer Learning,...), or even create your own neural network ! Find a relevant methodology, evaluate several architectures (use of dropout, batch Normalisation, use of pretrained netorks with fine tuning... ), objective functions, optimizers.... Take a look at the influence of the parameters (learning rate, batch size, ...). Be imaginative !!\n","\n","\n","## Evaluation\n","You have to write a final report in a **jupyter notebook**. The code will be done in Python, the comments in Markdown. \n","In this report, you will detail all the steps that led you to the final results, the code you produce, all the experiments you made (different architectures, different parameters, the way you measure the performance of your method,...) with **relevant** comments.\n","\n","In order not to train all your models by myself, please save your **final** model using the [`save_weights`](https://keras.io/api/models/model_saving_apis/) method. For example:\n","\n","`model = tf.keras.Sequential([tf.keras.layers.Dense(5, input_shape=(3,)),tf.keras.layers.Softmax()])`\n","\n","`model.compile(...)`\n","\n","`model.fit(...)`\n","\n","`model.save_weights('mymodel.h5')`\n","\n","Please provide the `.h5` file as well as the full jupyter notebook.\n","\n","\n","\n","I have a validation set to validate your trained network. I will run your model on this dataset to measure the classification accuracy. \n","\n","To give the final mark, the following criteria will be used:\n","- I will rank you w.r.t. to the accuracy on the validation set. The ranking will provide a part (8/20) of the note (8 points for the best accuracy down to 2 points for the worst)\n","- The report will provide the remaining 12 points. I will assess the experiments you have made, the final model itself, the comments and the conclusions you have drawn, the results you  have obtained\n","\n","The report, as well as the `.h5`file, are due **July 5th 2021** on the GRISP  platform."]},{"cell_type":"markdown","metadata":{"id":"SC95pJe8JPp5"},"source":["## Colab initialization\n","This is our Colab initialization. We implemented an absolute path, stored in the PATH_TO_ROOT variable, in order not to have to write it over and over again."]},{"cell_type":"code","metadata":{"id":"9JZcgMAboLGA"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","PATH_TO_ROOT = \"/content/drive/MyDrive/Colab-Notebooks/Deep-Learning-Python/Challenge/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"27j5J_NJoLF_"},"source":["## Imports\n","We have imported few libraries and some of them weren't used eventually because we have changed our ideas about how to solve the problem. At first our main idea was to use an already existing neural network or CNN. Hence why we imported things like ResNet, InceptionResNetV2, etc. \n","\n"]},{"cell_type":"code","metadata":{"id":"VPurT1pSztrV"},"source":["# Alredy defined imports\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import time\n","from PIL import Image\n","import glob\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Predefined nerual networks\n","from tensorflow.keras.applications import VGG19,ResNet50,MobileNetV2, InceptionResNetV2\n","# All imports needed to build our own model\n","from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.optimizers import Adam\n","# Label handling\n","from keras.utils import np_utils\n","# Libraries used in attempts to extract matrices from images\n","from torch.nn.functional import interpolate\n","from torchvision.transforms import ToTensor\n","import scipy.misc\n","import matplotlib.image as img\n","# The library we eventually used for image reading\n","import imageio\n","import os\n","# Libraries we used to handle conversions of images-to-array and vice-versa\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.preprocessing.image import array_to_img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pNKmYDQqoLGA"},"source":["## Data\n","Our goal was to recognize images from five differet classes, as in the code below. We used pandas to conert .csv files with information about path, name and label of the image, to pandas dataframes. \n","We used again the PATH_TO_ROOT variable, that as defined above.\n"]},{"cell_type":"code","metadata":{"id":"ahg1yezWoLGA"},"source":["# The five classes we aim at recognizing\n","classes = [\"basket\",\"eye\",\"binoculars\",\"rabbit\",\"hand\"] \n","\n","# Use the correct directory\n","train = pd.read_csv(PATH_TO_ROOT + 'train.csv')\n","test = pd.read_csv(PATH_TO_ROOT + 'test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-W-R3hmJsyuW"},"source":["This block of code has the purpose of giving an example of the dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"-CfLGS0doLGB","colab":{"base_uri":"https://localhost:8080/","height":540},"executionInfo":{"status":"ok","timestamp":1624290012148,"user_tz":-120,"elapsed":1839,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"865709aa-5334-4c88-f992-be96732904d3"},"source":["## SHOWING SAMPLES ##\n","\n","plt.figure(figsize=(18,9))\n","for i in range(0,5):\n","    ax= plt.subplot(3,2 ,i+1)\n","    mydata = pd.read_csv(PATH_TO_ROOT + \"train.csv\",skiprows = [1], nrows=1)\n","    im = Image.open(PATH_TO_ROOT + 'images/'+classes[i]+'/'+ os.listdir(PATH_TO_ROOT + \"images/\"+classes[i])[0])\n","    fig=ax.imshow(im)\n","    plt.title(classes[i])\n","    fig.axes.get_xaxis().set_visible(False)\n","    fig.axes.get_yaxis().set_visible(False)\n","plt.show()    "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1296x648 with 5 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"UZse5fqVoLGC"},"source":["# Up to you now"]},{"cell_type":"markdown","metadata":{"id":"ofVoT1NZAJok"},"source":["## Unsuccessful tries"]},{"cell_type":"markdown","metadata":{"id":"Zd3qqDADBN-J"},"source":["### ResNet\n","Unsuccesful try with ResNet. We decided not to use it, or any other CNN, because we had trouble with upscaling images to 32x32, which is the minimum size for all those already existing neural networks.\n"]},{"cell_type":"code","metadata":{"id":"TgftzbXQoLGC"},"source":["# DO NOT RUN !!!\n","\n","## UNSUCCESSFUL TRY WITH RESNET ##\n","\n","def newModel(input_shape,stop_freeze):\n","    # Uploading the model\n","    pretrained_model = tf.keras.applications.InceptionResNetV2(input_shape=[*input_shape,3], include_top=False)\n","  \n","    # Suppression of the classification layer\n","    pretrained_model.layers.pop()\n","\n","    # Freezing all the layers, except the last stop_freeze\n","    for layer in pretrained_model.layers[:-stop_freeze]:\n","        layer.trainable = False\n","\n","    # New classifier on top of the network\n","    model = tf.keras.Sequential([pretrained_model,\n","                                tf.keras.layers.Flatten(),\n","                                tf.keras.layers.Dense(num_classes, activation='softmax')])\n","    return model\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M6anPYLQBQ1b"},"source":["### Image extracting\n","Attempt at converting the images to matrices, using the open function and numpy arrays. It did not work for us because it took too long. However, we figured out later that the problem were the numpy arrays."]},{"cell_type":"code","metadata":{"id":"i2HFOQyngpJQ","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1624289988977,"user_tz":-120,"elapsed":499,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"c3eb3bb0-5656-4b77-dd47-248b2794d0b3"},"source":["# DO NOT RUN !!!\n","\n","## UNSUCCESSFUL TRY TO OPEN IMAGES ##\n","\n","index = 0\n","# Iterating all image path\n","for item in features_np:\n","    # Reading the image\n","    res = imageio.imread(features_np[index])\n","    # Open the image\n","    im = Image.open(item)\n","    # Appending it to the numpy array\n","    data = np.asarray(im)\n","    np.append(images_np, data)\n","    # Printing the index to have an idea of the performance\n","    print(index)\n","    index += 1"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-4a3c1f63807a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Iterating all image path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_np\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Reading the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'features_np' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"VbPOU7u0AtSy"},"source":["## Successful implementation"]},{"cell_type":"markdown","metadata":{"id":"rjEmkKjpBJAq"},"source":["### Conversion of images to matrices of values\n","Since the append function was too slow with numpy arrays, we decided to employ a preinstalled python array, and to convert it to numpy after all the matrices had been appended to the array. In the end, in order to handle such matrices outside of the virtual machine, we chose to save them as .npy binary file, since it offered by far the best performances.\n","\n","Procedure for the train dataset."]},{"cell_type":"code","metadata":{"id":"4p0Mu8RYAYCK"},"source":["## TRAIN DATA SET EXTRACTION ##\n","\n","# Creating a list of the labels from the pandas dataframe\n","labels_np = np.array(train.loc[:,\"class_label\"])\n","# Doing the same thing for the relative path\n","features_np = np.array(PATH_TO_ROOT +  \"images/\" + train.loc[:,\"relative_path\"])\n","# Empty list to store matrices\n","images = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y13cT2YsCr4b"},"source":["# Iterating all paths of the train dataset\n","for i in range(len(features_np)):\n","    # Reading the image from the file\n","    res = imageio.imread(features_np[index])\n","    # Loadding the image into a variable\n","    im = load_img(features_np[i])\n","    # Converting it to array \n","    data = img_to_array(im)\n","    # Appending it to the images list\n","    images.append(data)\n","    print(i)\n","\n","# Converting images to numpy\n","images_np = np.asarray(images)\n","\n","# Displaying dimensions of the images for testing reasons, in order to see that the conversion worked\n","display((len(images_np)))\n","display(images_np[0].shape)\n","\n","# Saving the numpy arrqay of matrices in a .npy binary file\n","np.save(PATH_TO_ROOT + \"binary_test.npy\", images_np)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPzFfZ_EyCyE"},"source":["Same procedure for the test dataset."]},{"cell_type":"code","metadata":{"id":"ejJQ1C50AjSB"},"source":["## TEST DATA SET EXTRACTION ##\n","\n","labels_np_test = np.array(test.loc[:,\"class_label\"])\n","features_np_test = np.array(PATH_TO_ROOT +  \"images/\" + test.loc[:,\"relative_path\"])\n","images_test = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbQzGNxXyxoJ"},"source":["# Iterating all paths of the test dataset\n","for i in range(len(features_np_test)):\n","    res = imageio.imread(features_np[index])\n","    im = load_img(features_np_test[i])\n","    data = img_to_array(im)\n","    images_test.append(data)\n","    print(i)\n","\n","images_np_test = np.asarray(images_test)\n","\n","display((len(images_np)))\n","display(images_np[0].shape)\n","\n","# Saving the numpy array of matrices to another .npy binary file\n","np.save(PATH_TO_ROOT + \"binary_test.npy\", images_np_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-_WidizB13n"},"source":["### Loading saved matrices back to VM\n","Uploading the .npy file containing the array of matrices in the program"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119},"id":"yTQHwiI-ryyL","executionInfo":{"status":"ok","timestamp":1624290396611,"user_tz":-120,"elapsed":9492,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"4669a6cb-5f6e-473a-e320-a10a904ee564"},"source":["## LOADING FROM .NPY FILE ##\n","# Loading the train and test dataset\n","out_train_X = np.load(PATH_TO_ROOT + \"binary.npy\")\n","out_test_X = np.load(PATH_TO_ROOT + \"binary_test.npy\")\n","\n","## Train dataset ##\n","# Displaying the dimensions of an element to see if convertion from .npy file was done correctly\n","display((len(out_train_X)))\n","display(out_train_X.shape)\n","display(out_train_X[0].shape)\n","\n","## Test dataset ##\n","# Displaying the dimensions of an element to see if convertion from .npy file was done correctly\n","display((len(out_test_X)))\n","display(out_test_X.shape)\n","display(out_test_X[0].shape)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["75000"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["(75000, 28, 28, 3)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["(28, 28, 3)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["25000"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["(25000, 28, 28, 3)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["(28, 28, 3)"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"pQrcfBuFCKDp"},"source":["### Data and label preparation\n","We then normalized the matrices both from test and train datasets, in order to have better results with the CNN. We tried to flatten them as well, but then we realised it did not make sense, since it must be done at the end of the CNN model.\n","\n","We chose a three channels RGB format for the input, even though the images were originally black and white.\n","\n","We normalized the values to range 0-1 by division by 255 because the pictures were RGB 256."]},{"cell_type":"code","metadata":{"id":"qnIkiQjwyQTj","colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"status":"ok","timestamp":1624290400560,"user_tz":-120,"elapsed":624,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"c0000254-e241-4a47-9d79-9b779576e6f9"},"source":["## NORMALIZATION AND FLATTENING ##\n","train_X_norm = out_train_X / 255.0\n","test_X_norm = out_test_X / 255.0\n","\n","##Attempt at flattening matrices\n","#arr_train = []\n","#for elem in out_train_X:\n","#    arr_train.append(elem.flatten()/255)\n","\n","#arr_test = []\n","#for elem in out_test_X:\n","#    arr_test.append(elem.flatten()/255)\n","\n","#train_X_norm = np.asarray(arr_train).astype('float32')\n","#test_X_norm = np.asarray(arr_test).astype('float32')\n","\n","#testing that the flattening procedure was successful\n","print(train_X_norm.shape)\n","imageLike = train_X_norm[50000]\n","image = plt.imshow(imageLike)\n","print(imageLike.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(75000, 28, 28, 3)\n","(28, 28, 3)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Vj-E-YMO1Ujc"},"source":["We used np_utils to cathegorize the labels from both train and test datsets, in order to be able to use them in the CNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y41Q9p67_GNn","executionInfo":{"status":"ok","timestamp":1624290403753,"user_tz":-120,"elapsed":223,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"be6e5595-f71b-4877-8a3f-87352e34e6af"},"source":["## LABEL CATHEGORIZATION ##\n","\n","y_train = np_utils.to_categorical(labels_np)\n","y_test = np_utils.to_categorical(labels_np_test)\n","num_classes = y_test.shape[1]\n","print(num_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zWrHbzBy1v1M"},"source":["##Building our CNN\n","\n","We took inspiration from the neural network described in the article:\n","\n","https://www.datacareer.de/blog/quick-draw-classifying-drawings-with-python/, \n","\n","since it offered really high performances on a similar task, with 28x28 images. The model consists of several convolutional layers and max pooling layers, with one dropout layer. At the end we flattened the output of the neural network, thanks to a dense layer. For the model we always utilized the relu activation, but we used softmax at the end, as the task is about cathegorical classication. Our model used cathegorical cross entropy as loss function, and the Adam optimizer was the one which performed the best.\n"]},{"cell_type":"markdown","metadata":{"id":"KP7MRdpgDohm"},"source":["\n","Eventually we tuned our hyperparamters, taking inspiration from the articles \n","\n","https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/#:~:text=The%20number%20of%20examples%20from,dynamics%20of%20the%20learning%20algorithm.&text=Batch%20size%20controls%20the%20accuracy,gradient%20when%20training%20neural%20networks\n","\n","for the batch size, \n","\n","https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n","\n","for the learning rate. "]},{"cell_type":"markdown","metadata":{"id":"THKOCSZ5Dr5E"},"source":["After many trials with many different hyperparameters, we found that these settings are the ones that make the model perform the best. We started with a largr number of epochs, like 25, but it turned out that the model performed better at around 10 to 12 epochs. We also tried with larger and smaller learning rates, but we found this to be the optimal. Same goes for the batch size."]},{"cell_type":"code","metadata":{"id":"ph2Q897hAvg_"},"source":["## CNN MODEL BUILDING##\n","\n","# Hyper parameters\n","lr = 0.001\n","num_epochs = 10\n","batch_size = 128\n","\n","# We wanted to define the function makeModel(), because we need to call it again while loading the weights\n","def makeModel():\n","  # Create model\n","  model = Sequential()\n","  # Adding layers\n","  model.add(\n","      Conv2D(30, \n","            (5, 5), \n","            input_shape=(28, 28, 3), \n","            activation='relu'))\n","  model.add(\n","      MaxPooling2D(\n","          (2, 2)))\n","  model.add(\n","      Conv2D(15, \n","            (3, 3), \n","            activation='relu'))\n","  model.add(\n","      MaxPooling2D(\n","          (2, 2)))\n","  model.add(\n","      Dropout(0.2))\n","  model.add(\n","      Flatten())\n","  model.add(\n","      Dense(128, \n","            activation='relu'))\n","  model.add(\n","      Dense(50, \n","            activation='relu'))\n","  model.add(\n","      Dense(num_classes, \n","            activation='softmax'))\n","  # Choosig optimizer and loss function\n","  adam = Adam (learning_rate=lr)\n","  model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","\n","  # See how the model looks like\n","  model.summary()\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mI7L5bG76L32"},"source":["We wanted to see the shapes of the matrices one last time, just to be sure. Then we created a model calling the makeModel() function we defined previously"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rO9HB-4kHhqh","executionInfo":{"status":"ok","timestamp":1624290410314,"user_tz":-120,"elapsed":675,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"816e3827-3130-4ae3-ed2f-46c2c88a2c21"},"source":["## MODEL CREATION ##\n","\n","print(\"Train\")\n","print(train_X_norm.shape)\n","print(y_train.shape)\n","print(\"Test\")\n","print(test_X_norm.shape)\n","print(y_test.shape)\n","\n","# Define model\n","model = makeModel()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train\n","(75000, 28, 28, 3)\n","(75000, 5)\n","Test\n","(25000, 28, 28, 3)\n","(25000, 5)\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 24, 24, 30)        2280      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 12, 12, 30)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 10, 10, 15)        4065      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 5, 5, 15)          0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 5, 5, 15)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 375)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               48128     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 50)                6450      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 5)                 255       \n","=================================================================\n","Total params: 61,178\n","Trainable params: 61,178\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qZF_j-iQD2fh"},"source":["### Model fitting\n","We then fitted the model, testing all the different hyperparameters, to find out what was the best version of it. Then we evaluated it and printed the error\n","\n","We train on our dataset and reached an accuracy of 95.1%"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6M87e9MFrhI","executionInfo":{"status":"ok","timestamp":1624291043676,"user_tz":-120,"elapsed":630301,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"d7ab1e26-17c6-44a4-85a1-f481a1c8c192"},"source":["## MODEL FIT ##\n","\n","# Fit the model\n","model.fit(train_X_norm, y_train, validation_data=(test_X_norm, y_test), epochs=num_epochs, batch_size=batch_size)\n","# Final evaluation of the model\n","scores = model.evaluate(test_X_norm, y_test, verbose=0)\n","print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","586/586 [==============================] - 63s 105ms/step - loss: 0.4538 - accuracy: 0.8491 - val_loss: 0.2711 - val_accuracy: 0.9103\n","Epoch 2/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.2616 - accuracy: 0.9138 - val_loss: 0.2090 - val_accuracy: 0.9307\n","Epoch 3/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.2160 - accuracy: 0.9286 - val_loss: 0.1867 - val_accuracy: 0.9374\n","Epoch 4/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.1901 - accuracy: 0.9361 - val_loss: 0.1743 - val_accuracy: 0.9410\n","Epoch 5/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.1743 - accuracy: 0.9406 - val_loss: 0.1635 - val_accuracy: 0.9438\n","Epoch 6/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.1622 - accuracy: 0.9444 - val_loss: 0.1659 - val_accuracy: 0.9447\n","Epoch 7/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.1523 - accuracy: 0.9480 - val_loss: 0.1542 - val_accuracy: 0.9485\n","Epoch 8/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.1436 - accuracy: 0.9505 - val_loss: 0.1534 - val_accuracy: 0.9480\n","Epoch 9/10\n","586/586 [==============================] - 62s 106ms/step - loss: 0.1353 - accuracy: 0.9542 - val_loss: 0.1539 - val_accuracy: 0.9495\n","Epoch 10/10\n","586/586 [==============================] - 63s 107ms/step - loss: 0.1310 - accuracy: 0.9545 - val_loss: 0.1507 - val_accuracy: 0.9506\n","Large CNN Error: 4.94%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"taVluY8AEBMM"},"source":["### Saving weights"]},{"cell_type":"markdown","metadata":{"id":"obL8ilrW7FHc"},"source":["We saved the weights. The name of the file containing the weights is defined by the accuracy of the model, so that it would be easier for us to recognize our best option"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FdkE5WbRCuV","executionInfo":{"status":"ok","timestamp":1624291066960,"user_tz":-120,"elapsed":7304,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"b1538fa2-6471-45d5-f470-bdcfaa3cc946"},"source":["## EVALUATION AND SAVING ##  \n","scores = model.evaluate(test_X_norm, y_test, verbose=1)\n","print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n","print(\"Loss = {0:5.3f}, Accuracy = {1:5.3f}\".format(scores[0], scores[1]))\n","\n","name = \"\"\n","name = 'weights_v1_{acc}.h5'.format(acc = scores[1])\n","print(name)\n","model.save_weights(PATH_TO_ROOT + name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["782/782 [==============================] - 7s 9ms/step - loss: 0.1507 - accuracy: 0.9506\n","Large CNN Error: 4.94%\n","Loss = 0.151, Accuracy = 0.951\n","weights_v1_0.9505599737167358.h5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HP4Ldf7_EJam"},"source":["### Testing loaded model"]},{"cell_type":"markdown","metadata":{"id":"OoTEAOFy7-Wd"},"source":["To conclude with, we loaded the weights to have a final test and show how our model works in terms of prediction. For the prediction to work we had to feed the model an array of matrices, not just one picture: it needs four dimensions to work with.\n","\n","The model requires a (-,28,28,3) dimension.\n","\n","As a result of the prediction we received a matrice containing the probability of the model recognizing the pictures correctly. The higher the number the higher the probability of the model making the correct guess. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":758},"id":"z9UmlEVGSocM","executionInfo":{"status":"ok","timestamp":1624295109064,"user_tz":-120,"elapsed":693,"user":{"displayName":"Lukáš Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjhc6-3A_r5HseANLtc6CtzkMqX-lIQGbKWtzPIN48=s64","userId":"14018385952919488740"}},"outputId":"6e29041d-f3b5-4d65-ef1b-d8759b58b4db"},"source":["## LOADING WEIGHTS ##\n","FILE_NAME = \"weights_v1_0.9505599737167358.h5\"\n","loaded_model = makeModel()\n","loaded_model.load_weights(PATH_TO_ROOT + FILE_NAME)\n","\n","# Testing the sample\n","range = 23000\n","input = train_X_norm[range:range+1]\n","print(input.shape)\n","\n","# Creating prediction\n","pred = loaded_model.predict(input)\n","res = np.argmax(pred)\n","print(\"Prediction: {a}\".format(a = classes[res]))\n","plt.imshow(train_X_norm[range:range+1].reshape(28,28,3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 24, 24, 30)        2280      \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 12, 12, 30)        0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 10, 10, 15)        4065      \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 5, 5, 15)          0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 5, 5, 15)          0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 375)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 128)               48128     \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 50)                6450      \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 5)                 255       \n","=================================================================\n","Total params: 61,178\n","Trainable params: 61,178\n","Non-trainable params: 0\n","_________________________________________________________________\n","(1, 28, 28, 3)\n","Prediction: eye\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9fc4e29b50>"]},"metadata":{"tags":[]},"execution_count":41},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}